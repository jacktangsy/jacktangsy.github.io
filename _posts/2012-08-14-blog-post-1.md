---
title: 'The Stochastic Block Model'
date: 2025-01-04
permalink: /posts/2025/01/The Stochastic Block Model/
tags:
  - Statistical Network Analysis
---

We denote a network with $n$ nodes by its adjacency matrix $\boldsymbol{A} \in \mathbb{R}^{n \times n}$, where $A_{ij} = 1$ if there is an edge (link) between nodes $i$ and $j$ and $A_{ij} = 0$ otherwise. We do not allow for self-edges (self-loops), i.e., the diagonal entries of $\boldsymbol{A}$ are all zero.

Among various models, the stochastic block model (<a href="https://www.sciencedirect.com/science/article/pii/0378873383900217" target="_blank">SBM</a>) has attracted much attention and is arguably the best studied and most commonly used. Below, we briefly review its setting.

Suppose there are $K$ communities. Each node belongs to only one of the communities. Let $\boldsymbol{c} = (c_1, \ldots, c_n) \in \left\{ 1, \ldots, K \right\}^n$ denote the true community labels of the nodes, and assume $c_i$'s are i.i.d. categorical variables with parameter vector $\boldsymbol{\pi} = (\pi_1, \ldots, \pi_K)$, where $\pi_k \geq 0$ for all $1 \leq k \leq K$ and $\sum_{k=1}^K \pi_k = 1$. 

Conditional on the community labels, the edge variables $A_{ij}$'s are independent Bernoulli variables with 

$$
\mathbb{E} \left[ A_{ij} \mid \boldsymbol{c} \right] = P(A_{ij} = 1 \mid \boldsymbol{c}) = P_{c_i c_j},
$$

where $\boldsymbol{P} \in [0, 1]^{K \times K}$ is the symmetric edge-probability matrix with the $kl$-entry $P_{kl}$ characterizing the probability of connection between nodes in communities $k$ and $l$. Let $\boldsymbol{\Omega} = (\boldsymbol{\pi}, \boldsymbol{P})$.

Why Estimation via EM is Intractable
======
It would be natural and logical to treat $\boldsymbol{c}$ as latent variables and attempt to fit the SBM using EM algorithm. The log-likelihood for complete data (i.e., $\boldsymbol{A}$ and $\boldsymbol{c}$) is computed as
$$
\begin{align}
    \ell(\boldsymbol{\Omega}; \boldsymbol{A}, \boldsymbol{c}) &= \log P(\boldsymbol{A}, \boldsymbol{c} \mid \boldsymbol{\Omega}) \\
    &= \log P(\boldsymbol{c} \mid \boldsymbol{\pi}) + \log P(\boldsymbol{A} \mid \boldsymbol{c}, \boldsymbol{P}) \\
    &= \sum_{i=1}^n \log P(c_i \mid \boldsymbol{\pi}) + \sum_{i<j} \log P(A_{ij} \mid c_i, c_j, \boldsymbol{P}) \\
    &= \sum_{i=1}^n \sum_{k=1}^K I(c_i = k) \log \pi_k \\
    &\quad + \sum_{i<j} \left[ A_{ij} \log P(A_{ij} = 1 \mid c_i, c_j, \boldsymbol{P}) + (1 -A_{ij}) \log P(A_{ij} = 0 \mid c_i, c_j, \boldsymbol{P}) \right] \\
    &= \sum_{i=1}^n \sum_{k=1}^K I(c_i = k) \log \pi_k \\
    &\quad +\sum_{i<j} \sum_{k=1}^K \sum_{l=1}^K I(c_i = k) I(c_j = l) \left[ A_{ij} \log P_{kl} + (1 -A_{ij}) \log \left( 1 - P_{kl} \right) \right].
\end{align}
$$
